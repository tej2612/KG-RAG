# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rb92RqoE9ab7y14bQv8tPu6kl2NpBS8i

# Setup and Install Dependencies

The following code installs and upgrades the required Python packages for the project:

ollama pull mxbai-embed-large
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade --quiet  langchain langchain-community langchain-ollama langchain-experimental neo4j tiktoken yfiles_jupyter_graphs python-dotenv json-repair langchain-openai langchain_core

# Commented out IPython magic to ensure Python compatibility.
# %pip install -U langchain-ollama

# Commented out IPython magic to ensure Python compatibility.
# %pip install -U mixedbread-ai sentence-transformers

"""# Import Libraries and Load Environment Variables
This code imports the necessary libraries for LangChain, Neo4j, Ollama, and related integrations. It also loads environment variables from a .env file.
"""

from langchain_core.runnables import  RunnablePassthrough
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langchain_core.output_parsers import StrOutputParser
from langchain_community.graphs import Neo4jGraph
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.chat_models import ChatOllama
from langchain_experimental.graph_transformers import LLMGraphTransformer
from neo4j import GraphDatabase
from yfiles_jupyter_graphs import GraphWidget
from langchain_community.vectorstores import Neo4jVector
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars
from langchain_ollama import OllamaEmbeddings
import os,json,random,datetime
from langchain_experimental.llms.ollama_functions import OllamaFunctions
from neo4j import  Driver
from dotenv import load_dotenv
import json
from typing import Dict, List, Any
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
#from langchain.llms import OllamaFunctions
import logging
import random
import re

load_dotenv()

"""## Example Crime Movie"""

fn = 'plot'

graph = Neo4jGraph()

"""# Load and Split Documents

This code loads the movie plot and summary file, splits it into smaller chunks for processing, and outputs details about the resulting documents:

"""

loader1= TextLoader(file_path=rf"{fn}.txt")
docs1 = loader1.load()


text_splitter1 = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
documents1 = text_splitter1.split_documents(documents=docs1)

print(documents1)
print(type(documents1))
print(len(documents1))

"""This code loads the movie review file that has both spoiler and non spoiler and, splits it into smaller chunks for processing, and outputs details about the resulting documents:

This code is to just save the processes documents before creating a graph out of it
"""

def document_to_dict(review_document):

    if isinstance(review_document, dict):
        return review_document
    elif hasattr(review_document, "__dict__"):

        result = {key: value for key, value in review_document.__dict__.items()}

        for key, value in result.items():
            if isinstance(value, datetime.datetime):
                result[key] = value.isoformat()  # Convert datetime to ISO string
            # Add more custom types if needed (e.g., handling lists, sets, etc.)
        return result
    else:
        raise TypeError(f"Cannot serialize object of type {type(review_document)}")

def save_reviews_locally(documents, file_name="final_document_godfather.json"):
    # Convert all review_documents to dictionaries to ensure they are serializable
    documents_dict = [document_to_dict(doc) for doc in documents]

    with open(file_name, "w") as file:
        json.dump(documents_dict, file, indent=4)  # Save with pretty formatting

    print(f"Reviews saved to {file_name}")

save_reviews_locally(documents1)

"""# Initialize LLM and Graph Transformer

This code initializes a large language model (LLM) with specific parameters and sets up a graph transformer for processing:

"""

llm = OllamaFunctions(model="llama3.1", temperature=0.2, format="json")

llm_transformer = LLMGraphTransformer(llm=llm)

"""# Convert Documents to Graph Format

This code converts the processed documents into graph-compatible format using the LLM transformer:

"""

graph_documents = llm_transformer.convert_to_graph_documents(documents1)

print(graph_documents)
print(type(graph_documents))

"""This code is to just save the processes *GRAPH* documents locally"""

graph.add_graph_documents(
    graph_documents,
    baseEntityLabel=True,
    include_source=True
)

"""# Add Graph Documents to Neo4j and Display Graph

This code adds the generated graph documents to a Neo4j graph database and displays the graph using a visualization widget:

"""

def showGraph():
    driver= GraphDatabase.driver(
        uri= os.environ["NEO4J_URI"],
        auth=(os.environ["NEO4J_USERNAME"],
              os.environ["NEO4J_PASSWORD"]))
    session= driver.session()
    widget= GraphWidget(graph= session.run("MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t").graph())
    widget.node_label_mapping= 'id'
    return widget

showGraph()

"""# Graph Image"""

import numpy as np
from sklearn.linear_model import LinearRegression
from typing import List, Dict

class GraphAnalyzer:
    def __init__(self, graph: Neo4jGraph):
        self.graph = graph

    def get_basic_metrics(self):
        """Get basic graph metrics like node and edge counts."""
        metrics = self.graph.query("""
        MATCH (n)
        WITH count(n) as nodes
        MATCH ()-[r]->()
        RETURN nodes, count(r) as relationships,
               count(DISTINCT type(r)) as relationship_types
        """)
        return metrics[0] if metrics else None

    def get_node_label_distribution(self):
        """Get distribution of node labels in the graph."""
        return self.graph.query("""
        MATCH (n)
        WITH labels(n) as labels
        UNWIND labels as label
        WITH label, count(*) as count
        RETURN label, count
        ORDER BY count DESC
        """)

    def get_relationship_distribution(self):
        """Get distribution of relationship types."""
        return self.graph.query("""
        MATCH ()-[r]->()
        WITH type(r) as rel_type, count(*) as count
        RETURN rel_type, count
        ORDER BY count DESC
        """)

    def get_central_nodes(self, limit=10):
        """Find the most central nodes based on degree centrality."""
        return self.graph.query(f"""
        MATCH (n)
        WITH n, size([(n)-[]-() | 1]) as degree
        RETURN n.id as node, degree
        ORDER BY degree DESC
        LIMIT {limit}
        """)

    def get_node_connectivity(self):
        """Analyze node connectivity patterns."""
        return self.graph.query("""
        MATCH (n)
        WITH n,
             size([(n)-[]->()] | 1) as outDegree,
             size([(n)<-[]-() | 1]) as inDegree
        RETURN
            avg(outDegree) as avg_out_degree,
            avg(inDegree) as avg_in_degree,
            max(outDegree) as max_out_degree,
            max(inDegree) as max_in_degree
        """)

    def find_isolated_nodes(self):
        """Find nodes with no relationships."""
        return self.graph.query("""
        MATCH (n)
        WHERE NOT exists((n)-[]->()) AND NOT exists((n)<-[]-())
        RETURN n.id as node
        """)

    def get_graph_density(self):
        """Calculate graph density."""
        return self.graph.query("""
        MATCH (n)
        WITH count(n) as nodes
        MATCH ()-[r]->()
        WITH nodes, count(r) as relationships
        RETURN
            CASE
                WHEN nodes <= 1 THEN 0
                ELSE (relationships * 1.0) / (nodes * (nodes-1))
            END as density
        """)[0]['density']

    def find_shortest_paths(self, start_node, end_node):
        """Find shortest paths between two nodes."""
        return self.graph.query(f"""
        MATCH path = shortestPath((a)-[*]-(b))
        WHERE a.id = '{start_node}' AND b.id = '{end_node}'
        RETURN [node in nodes(path) | node.id] as path,
               length(path) as path_length
        """)

    def predict_node_connectivity(self, features: List[Dict]):
        """
        Predict node connectivity using linear regression.

        Args:
            features: List of node feature dictionaries

        Returns:
            Predicted connectivity scores
        """
        X = np.array([list(feature.values()) for feature in features])
        y = np.array([feature.get('current_connectivity', 0) for feature in features])

        model = LinearRegression()
        model.fit(X, y)

        return model.predict(X)

    def detect_community_structures(self, resolution=1.0):
        """
        Detect community structures using Louvain method.

        Args:
            resolution: Community detection resolution parameter

        Returns:
            Communities and their node compositions
        """
        return self.graph.query(f"""
        CALL algo.louvain.stream({{resolution: {resolution}}})
        YIELD nodeId, communityId
        WITH algo.getNodeById(nodeId) as node, communityId
        RETURN communityId, collect(node.id) as community_nodes
        """)

    def calculate_graph_entropy(self):
        """
        Calculate graph entropy to measure structural complexity.

        Returns:
            Graph entropy value
        """
        label_distribution = self.get_node_label_distribution()
        total_nodes = sum(row['count'] for row in label_distribution)

        entropy = 0
        for row in label_distribution:
            proportion = row['count'] / total_nodes
            entropy -= proportion * np.log2(proportion)

        return entropy

    def predict_node_importance(self, node_features):
        """
        Predict node importance using machine learning techniques.

        Args:
            node_features: Features of nodes

        Returns:
            Importance scores for nodes
        """
        # Simple example using linear regression
        X = np.array([list(feature.values()) for feature in node_features])
        model = LinearRegression()
        model.fit(X, np.arange(len(node_features)))

        return model.predict(X)

    def advanced_graph_summary(self):
        """
        Generate an advanced graph analysis summary.
        """
        try:
            print("\n=== Advanced Graph Analysis ===")

            # Basic metrics
            metrics = self.get_basic_metrics()
            print(f"Nodes: {metrics['nodes']}, Relationships: {metrics['relationships']}")

            # Graph density
            density = self.get_graph_density()
            print(f"Graph Density: {density:.4f}")

            # Graph entropy
            entropy = self.calculate_graph_entropy()
            print(f"Graph Entropy: {entropy:.4f}")

            # Community detection
            communities = self.detect_community_structures()
            print(f"Number of Communities: {len(communities)}")

        except Exception as e:
            print(f"Advanced analysis error: {str(e)}")

    def print_summary(self):
        """Print a comprehensive summary of the graph."""
        try:
            metrics = self.get_basic_metrics()
            print(f"\n=== Graph Summary ===")
            print(f"Total Nodes: {metrics['nodes']}")
            print(f"Total Relationships: {metrics['relationships']}")
            print(f"Relationship Types: {metrics['relationship_types']}")

            print("\n=== Top 10 Node Label Distribution ===")
            for row in self.get_node_label_distribution()[:10]:
                print(f"{row['label']}: {row['count']}")

            print("\n=== Top 10 Relationship Distribution ===")
            for row in self.get_relationship_distribution()[:10]:
                print(f"{row['rel_type']}: {row['count']}")

            print("\n=== Top Central Nodes ===")
            for row in self.get_central_nodes(5):
                print(f"Node: {row['node']}, Connections: {row['degree']}")


        except Exception as e:
            print(f"Error generating summary: {str(e)}")

# Assuming you have a Neo4j graph connection

# Create analyzer instance
analyzer = GraphAnalyzer(graph)

# Print comprehensive summary
analyzer.print_summary()

# Get specific metrics
central_nodes = analyzer.get_central_nodes()
print("\nMost connected nodes:")
for node in central_nodes:
    print(f"Node: {node['node']}, Connections: {node['degree']}")

# Additional method calls examples
node_labels = analyzer.get_node_label_distribution()
graph_density = analyzer.get_graph_density()
isolated_nodes = analyzer.find_isolated_nodes()
#node_connectivity = analyzer.get_node_connectivity()

# Advanced summary
analyzer.advanced_graph_summary()

"""# Link to access the graph on your browser...

https://www.yworks.com/yed-live/?file=https://gist.githubusercontent.com/namanbachhawat/63f6664254474bf2be38f3a7288608e6/raw/049d59593daeb583c0c6b3f386de68ab44eeca5f/The%20Godfather%201997

# Initialize Embeddings and Vector Index

This code initializes embeddings using the Ollama model and creates a vector index from an existing Neo4j graph. It also sets up a vector retriever for searching:
"""

embeddings = OllamaEmbeddings(
    model="mxbai-embed-large",
)

vector_index = Neo4jVector.from_existing_graph(
    embeddings,
    search_type="hybrid",
    node_label="Document",
    text_node_properties=["text"],
    embedding_node_property="embedding"
)
vector_retriever = vector_index.as_retriever()

"""# Create Fulltext Index in Neo4j

This code creates a fulltext index on the Neo4j database for efficient searching by the `id` property of nodes labeled `__Entity__`:

"""

driver = GraphDatabase.driver(
        uri = os.environ["NEO4J_URI"],
        auth = (os.environ["NEO4J_USERNAME"],
                os.environ["NEO4J_PASSWORD"]))

def create_fulltext_index(tx):
    query = '''
    CREATE FULLTEXT INDEX `fulltext_entity_id`
    FOR (n:__Entity__)
    ON EACH [n.id];
    '''
    tx.run(query)

# Function to execute the query
def create_index():
    with driver.session() as session:
        session.execute_write(create_fulltext_index)
        print("Fulltext index created successfully.")

# Call the function to create the index
try:
    create_index()
except:
    pass

# Close the driver connection
driver.close()

"""# Define Entity Extraction Model and Prompt

This code defines a model for extracting identifying information about entities, and sets up a prompt for extracting organization and person entities from text. It then creates a chain using the model for structured output:

"""

from pydantic import BaseModel, Field
from typing import List
from langchain.prompts.chat import ChatPromptTemplate

class Entities(BaseModel):
    """
    Identifying information about entities extracted from the text.
    """
    names: List[str] = Field(
        ...,
        description=(
            "A list of all person, organization, or business entities "
            "identified in the text."
        ),
    )

# Define the prompt template
prompt = ChatPromptTemplate.from_messages(
    [
        # System message: Provides context to the LLM about its role
        (
            "system",
            "You are tasked with extracting organization and person entities from the text."
        ),
        # Human message: Instruction to the LLM along with input format
        (
            "human",
            (
                "Use the specified format to extract information from the following input: "
                "{question}"
            )
        ),
    ]
)

# Configure the LLM with structured output for entity extraction
entity_chain = llm.with_structured_output(Entities)

qqq  = """The SPORTS COMMENTATOR is at the airport
and about to interview the world
heavyweight boxing champion, APOLLO CREED.
Creed is twenty-eight years old. He is a
tall, smooth-muscled black man with barely
a scar on his light coffee-colored face"""

entity_chain.invoke(qqq)

entity_chain.invoke("Who are Vito Corleone and Michael?")

"""# Fulltext Query Generation and Graph Retrieval

This code defines two functions:
1. `generate_full_text_query`: Generates a fulltext query using Lucene-like syntax to search for entities.
2. `graph_retriever`: Uses the `entity_chain` to extract entities from a question, then retrieves related entities from the Neo4j graph using a fulltext search query.

"""

def generate_full_text_query(input: str) -> str:
    words = [el for el in remove_lucene_chars(input).split() if el]
    if not words:
        return ""
    full_text_query = " AND ".join([f"{word}~2" for word in words])
    print(f"Generated Query: {full_text_query}")
    return full_text_query.strip()


def graph_retriever(question: str) -> str:
    result = ""
    try:
        entities = entity_chain.invoke(question)
        print(f"Extracted Entities: {entities.names}")  # Debug print

        for entity in entities.names:
            print(f"Searching for entity: {entity}")  # Debug print
            response = graph.query(
                """
                CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})
                YIELD node, score
                OPTIONAL MATCH (node)-[r]-(neighbor)
                RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output
                LIMIT 50
                """,
                {"query": entity},
            )
            result += "\n".join([el['output'] for el in response])
    except Exception as e:
        result = f"Error processing question: {str(e)}"
    return result


def full_retriever(question: str) -> str:
    try:
        graph_data = graph_retriever(question)
        vector_response = vector_retriever.invoke(question)
        if not vector_response:
            raise ValueError("Vector retriever returned no results.")

        vector_data = [el.page_content for el in vector_response if hasattr(el, 'page_content')]
        final_data = f"""Graph data:
{graph_data}
vector data:
{"#Document ".join(vector_data)}
        """
        return final_data
    except Exception as e:
        return f"Error retrieving full data: {str(e)}"

graph_retriever("Who is Vito Corleone?")

"""# Full Retriever Function

This function combines graph-based and vector-based data retrieval to provide comprehensive results. It collects relevant data from both a Neo4j graph and a vector store, then formats and returns the combined output.

"""

def full_retriever(question: str):
    graph_data = graph_retriever(question)
    vector_data = [el.page_content for el in vector_retriever.invoke(question)]
    final_data = f"""Graph data:
{graph_data}
vector data:
{"#Document ". join(vector_data)}
    """
    return final_data

def vector_only_retriever(question: str):
    vector_data = [el.page_content for el in vector_retriever.invoke(question)]
    return "".join(vector_data)

"""# Define Prompt Template and Chain

This code sets up a prompt template for answering questions based on a given context. It then creates a chain that integrates the context retrieval, question processing, and response generation using a large language model (LLM).

"""

template = """Answer the question based only on the following context:
{context}

If the context does not provide enough information, respond with "The context does not contain sufficient information to answer the question."

Use natural language, be concise but detailed where necessary, and do not repeat the question in the answer.

Question: {question}
Answer:
"""
prompt = ChatPromptTemplate.from_template(template)

chain = (
        {
            "context": full_retriever,
            "question": RunnablePassthrough(),
        }
    | prompt
    | llm
    | StrOutputParser()
)

entity_chain.invoke(input="Who is Vito Corleones enforcer?")

zz = full_retriever("What event forces Michael to take refuge in Sicily?")

print(type(zz))
print(len(zz))
print(zz)

print(type(zz2))
print(len(zz2))
print(zz2)

"""# Fulltext Search Query Execution

This code executes a fulltext search query in Neo4j to find nodes matching the search term `'don'`.
It then retrieves the relationships (mentions) connected to those nodes and returns the results.

"""

response = graph.query(
    """CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})
    YIELD node, score
    CALL (node) {  // Adding variable scope here
    WITH node
    MATCH (node)-[r:!MENTIONS]->(neighbor)
    RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output
    UNION ALL
    WITH node
    MATCH (node)<-[r:!MENTIONS]-(neighbor)
    RETURN neighbor.id + ' - ' + type(r) + ' -> ' + node.id AS output
    }
    RETURN output LIMIT 50
    """,
    {"query": 'don'},
)

print(response)

ans = chain.invoke(input='What event forces Michael to take refuge in Sicily?')

conexttt = full_retriever('What event forces Michael to take refuge in Sicily?')

print(type(conexttt))
ans

# Questions the graph RAG trained on The Godfather script might struggle to answer
questions_graph_might_struggle_with = [
    # Questions requiring subjective interpretation
    "Why does Michael Corleone feel regret later in his life?",
    "Does Vito Corleone’s moral code make him a good or bad person?",
    "How does the theme of power corrupting individuals apply to Michael’s journey?",

    # Questions about character psychology or motivation not explicitly in the script
    "What was Michael thinking during the baptism scene when he ordered the killings?",
    "What emotions drove Fredo to betray Michael?",
    "Why did Kay decide to leave Michael even after staying with him for so long?",

    # Questions about alternative scenarios
    "What would have happened if Sonny had survived and taken over the family?",
    "How might the story have changed if Apollonia had not been killed?",
    "What if Vito had never been shot—how would that affect the family dynamic?",

    # Questions about symbolism and thematic analysis
    "What does the use of oranges symbolize in the movie?",
    "How does the film depict the American Dream and its costs?",
    "Why is the concept of family loyalty both a strength and a weakness in the Corleone family?",

    # Questions about historical or external context
    "How does the Corleone family reflect real-life organized crime in America during that era?",
    "What role does the church play in shaping perceptions of morality in the film?",

    # Questions about events not directly shown in the movie
    "What happened in Michael’s military service that shaped his perspective?",
    "How did Vito establish his early power in the criminal world?",
    "What led Fredo to feel sidelined within the family?"
]



# List of non-factual questions about The Godfather
godfather_questions = [
    "What drives Michael Corleone to embrace the family business despite initially rejecting it?",
    "Do you think Michael ever truly reconciles with his decision to lead the family?",
    "Is Vito Corleone a 'moral' leader in his own way, despite his criminal background? Why or why not?",
    "How does Vito Corleone balance his role as a family man with being the head of a mafia empire?",
    "What role does Tom Hagen play in the family, and how does his non-Italian heritage impact his position?",
    "How does the concept of loyalty manifest in the actions of different characters?",
    "What does the film suggest about the interplay between power and family dynamics?",
    "Do you think Michael’s choices were inevitable given his family background, or did he have a real choice?",
    "How do the themes of tradition and modernity conflict in the Corleone family’s decisions?",
    "What do you think the toll of Michael’s leadership is on his personal relationships?"
]


# Define plot-based questions
plot_questions = [
    "Why does Michael Corleone decide to kill Sollozzo and McCluskey?",
    "What leads to Vito Corleone's assassination attempt, and how does it affect the family?",
    "Why is Michael sent to Sicily, and what happens to him there?",
    "How does Michael consolidate power after returning to the U.S.?",
    "What is the significance of the baptism scene at the end of the movie?",
]

# Character-Based Questions
character_questions = [
    "What is Vito Corleone's philosophy on family and loyalty?",
    "How does Michael Corleone's character evolve throughout the movie?",
    "What role does Tom Hagen play in the Corleone family?",
    "Who is Fredo Corleone, and what is his relationship with Michael?",
    "What is the significance of Kay Adams in Michael's life?"
]

# Theme-Based Questions
theme_questions = [
    "How does the movie portray the concept of power and its consequences?",
    "What role does tradition play in the story?",
    "How does the movie explore the theme of revenge?",
    "What does the movie suggest about the American Dream?",
    "How does the theme of loyalty influence the decisions of the characters?"
]

# Symbolism-Based Questions
symbolism_questions = [
    "What does the orange motif symbolize in the movie?",
    "What is the significance of Michael closing the door on Kay in the final scene?",
    "How is the Corleone family depicted as a metaphor for corporate America?",
    "What does the baptism scene symbolize?",
    "How is music used to highlight key moments in the story?"
]

# Dialogue-Based Questions
dialogue_questions = [
    "What is the significance of Vito's quote, 'I'm gonna make him an offer he can't refuse'?",
    "How does Michael's quote, 'It's not personal, Sonny. It's strictly business,' reflect his mindset?",
    "Why is the dialogue about 'women and children' significant in the family dynamic?",
    "What is the importance of the dialogue between Michael and Vito about taking over the family?",
    "How do the Corleone family's conversations reveal their internal conflicts?"
]



# Ask questions by category
def ask_questions(category_name, questions):
    print(f"### Asking {category_name} ###\n")
    for question in questions:
        try:
            print(f"Question: {question}")
            answer = chain.invoke(input=question)  # Replace with your RAG invocation method
            print(f"Answer: {answer}\n")
        except:
            print("error")
    print("\n")

ask_questions("Might struggle with :",questions_graph_might_struggle_with)

ask_questions("non factual : ", godfather_questions)

ask_questions("plot_questions",plot_questions)

ask_questions("Character-Based Questions", character_questions)

ask_questions("Theme-Based Questions", theme_questions)

ask_questions("Symbolism-Based Questions", symbolism_questions)

ask_questions("Dialogue-Based Questions", dialogue_questions)

"""# savee

"""

class MovieKGChainManager:
    def __init__(self, existing_chain=None):
        self.chain = existing_chain
        self.neo4j_credentials = {
            "uri": os.environ.get("NEO4J_URI"),
            "username": os.environ.get("NEO4J_USERNAME"),
            "password": os.environ.get("NEO4J_PASSWORD")
        }

        # Store component configurations
        self.llm_config = {
            "model": "llama3.1",
            "temperature": 0.3,
            "format": "json"
        }
        self.embeddings_config = {
            "model": "mxbai-embed-large"
        }
        self.template = template  # Use your existing template

    def save_chain_config(self, directory: str = "movie_kg_chain"):
        """Save the chain configuration and necessary components."""
        save_dir = directory


        # Save configurations
        config = {
            "neo4j_credentials": self.neo4j_credentials,
            "llm_config": self.llm_config,
            "embeddings_config": self.embeddings_config,
            "template": self.template
        }

        with open(save_dir+ "/config.json", "w") as f:
            json.dump(config, f, indent=4)

        print(f"Chain configuration saved to {save_dir}")

    @classmethod
    def load_chain_config(cls, directory: str = "movie_kg_chain"):
        """Load saved chain configuration and recreate the chain."""
        load_dir = directory

        # Load configuration
        with open(load_dir+"/config.json", "r") as f:
            config = json.load(f)

        # Set up components
        llm = OllamaFunctions(**config["llm_config"])
        embeddings = OllamaEmbeddings(**config["embeddings_config"])

        # Initialize graph
        graph = Neo4jGraph()

        # Initialize vector store
        vector_index = Neo4jVector.from_existing_graph(
            embeddings,
            search_type="hybrid",
            node_label="Document",
            text_node_properties=["text"],
            embedding_node_property="embedding"
        )
        vector_retriever = vector_index.as_retriever()

        # Initialize entity chain
        entity_chain = llm.with_structured_output(Entities)

        # Create prompt
        prompt = ChatPromptTemplate.from_template(config["template"])

        # Recreate the retrieval functions
        def graph_retriever(question: str) -> str:
            result = ""
            try:
                entities = entity_chain.invoke(question)
                if not hasattr(entities, 'names'):
                    raise ValueError("Entity chain did not return a valid 'names' attribute.")

                for entity in entities.names:
                    try:
                        response = graph.query(
                            """
                            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})
                            YIELD node, score
                            MATCH (node)-[r:MENTIONS]->(neighbor)
                            RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output
                            LIMIT 50
                            """,
                            {"query": entity},
                        )
                        result += "\n".join([el['output'] for el in response])
                    except Exception as e:
                        result += f"Error retrieving data for entity '{entity}': {str(e)}"
            except Exception as e:
                result = f"Error processing question: {str(e)}"
            return result

        def full_retriever(question: str):
            graph_data = graph_retriever(question)
            vector_data = [el.page_content for el in vector_retriever.invoke(question)]
            final_data = f"""Graph data:
            {graph_data}
            vector data:
            {"#Document ". join(vector_data)}
            """
            return final_data

        # Recreate the chain
        chain = (
            {
                "context": full_retriever,
                "question": RunnablePassthrough(),
            }
            | prompt
            | llm
            | StrOutputParser()
        )

        # Create manager instance with the recreated chain
        manager = cls(chain)
        print(f"Chain configuration loaded from {load_dir}")
        return manager

    def query(self, question: str) -> str:
        """Execute a query using the chain."""
        if self.chain is None:
            raise ValueError("Chain not initialized. Please load a chain first.")
        return self.chain.invoke(question)

chain.invoke(input="What event forces Michael to take refuge in Sicily?")

# Create a manager with your existing chain
chain_manager = MovieKGChainManager(chain)

# Save the configuration
chain_manager.save_chain_config("my_movie_chain3")

# Later, you can load the configuration and recreate the chain
loaded_manager = MovieKGChainManager.load_chain_config("my_movie_chain3")

# Use the loaded chain
result = loaded_manager.query("What event forces Michael to take refuge in Sicily?")
print(result)

"""# inference

# RAGAS
"""

!pip install ragas datasets pandas openpyxl python-dotenv langchain neo4j

import pandas as pd
import numpy as np
from ragas import evaluate
from ragas.metrics import (
    context_precision,
    faithfulness,
    answer_relevancy,
    context_recall,
    answer_correctness,
    answer_similarity
)
from datasets import Dataset
import os
import logging
from dotenv import load_dotenv
from langchain_community.vectorstores import Neo4jVector
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_experimental.llms.ollama_functions import OllamaFunctions
from langchain_core.output_parsers import StrOutputParser

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Initialize Local Ollama LLM and Embeddings for both RAG and Evaluation
llm = OllamaFunctions(model="llama3.1", temperature=0.2, format="json")
embeddings = OllamaEmbeddings(model="mxbai-embed-large")
eval_llm = ChatOllama(model="mistral", temperature=0.0, format="json")

# Vector Retriever Setup
vector_index = Neo4jVector.from_existing_graph(
    embeddings,
    search_type="hybrid",
    node_label="Document",
    text_node_properties=["text"],
    embedding_node_property="embedding"
)
vector_retriever = vector_index.as_retriever()

# Retrieval Function (Vector Only)
def vector_only_retriever(question: str, top_k=1):
    """Retrieve top K relevant contexts."""
    vector_data = vector_retriever.invoke(question)[:top_k]  # Get top-k contexts
    return [el.page_content for el in vector_data]  # Return list of top contexts

# Function to break the context into smaller chunks (e.g., based on token count or word count)
def chunk_context(context, chunk_size=150):
    """Break the context into chunks of specified size."""
    # Split the context into smaller chunks
    words = context.split()
    chunks = [ ' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size) ]
    return chunks

# RAG Chain Setup
template = """Answer the question based only on the following context:
{context}

If the context does not provide enough information, respond with "The context does not contain sufficient information to answer the question."

Use natural language, be concise but detailed where necessary, and do not repeat the question in the answer.

Question: {question}
Answer:
"""
prompt = ChatPromptTemplate.from_template(template)

# Modify chain to handle list context
chain = (
    {
        "context": lambda x: " ".join(vector_only_retriever(x)),  # Retrieve and merge top contexts
        "question": RunnablePassthrough(),
    }
    | prompt
    | llm
    | StrOutputParser()
)

# Evaluation Function for RAGAS Dataset
def evaluate_ragas_dataset(ragas_dataset, max_retries=3):
    for attempt in range(max_retries):
        try:
            logger.info(f"Evaluation attempt {attempt + 1}")
            result = evaluate(
                ragas_dataset,
                metrics=[context_precision, faithfulness, answer_relevancy, context_recall, answer_correctness, answer_similarity],
                llm=eval_llm,
                embeddings=embeddings,
                show_progress=True,
                batch_size=1  # Reduce batch size to mitigate timeout issues
            )
            return result
        except Exception as e:
            logger.error(f"Evaluation attempt {attempt + 1} failed: {str(e)}")
            if attempt == max_retries - 1:
                raise

# Main Evaluation Function
def evaluate_rag(input_file, output_file):
    # Read input Excel file
    df = pd.read_excel(input_file)

    # Prepare lists to store results
    model_answers = []
    retrieved_contexts = []

    # Generate answers and contexts
    for question in df['questions']:
        # Get retrieved context (top K relevant) - now a list
        top_contexts = vector_only_retriever(question, top_k=1)
        chunked_contexts = chunk_context(top_contexts[0])

        # Get model's answer using the final context
        model_answer = chain.invoke(question)

        model_answers.append(model_answer)
        retrieved_contexts.append(chunked_contexts)

    # Ensure columns exist, create them if missing
    if 'model_answers' not in df.columns:
        df['model_answers'] = model_answers

    if 'retrieved_contexts' not in df.columns:
        df['retrieved_contexts'] = retrieved_contexts

    # Add columns to dataframe
    df['model_answers'] = model_answers
    df['retrieved_contexts'] = retrieved_contexts

    # Prepare data for RAGAS
    data = {
        'question': df['questions'].tolist(),
        'ground_truth': df['ground_truths'].tolist(),
        'answer': df['model_answers'].tolist(),
        'contexts': df['retrieved_contexts'].tolist()
    }
    print(type(df['retrieved_contexts'].tolist()))
    for x in df['retrieved_contexts'].tolist():
        print(x)
    # Convert to HuggingFace Dataset
    ragas_dataset = Dataset.from_dict(data)

    # Evaluate using the custom evaluation function
    results = evaluate_ragas_dataset(ragas_dataset)

    return df, results

def write_ragas_results_to_excel(df, results, output_file):
    # Convert results to a DataFrame
    metrics_data = []
    for score in results.scores:
        metrics_data.append({
            'context_precision': score['context_precision'],
            'faithfulness': score['faithfulness'],
            'answer_relevancy': score['answer_relevancy'],
            'context_recall': score['context_recall'],
            'answer_correctness': score['answer_correctness'],
            'semantic_similarity': score['semantic_similarity']
        })

    metrics_df = pd.DataFrame(metrics_data)

    # Combine original dataframe with metrics
    combined_df = pd.concat([df, metrics_df], axis=1)

    # Write to Excel
    with pd.ExcelWriter(output_file) as writer:
        combined_df.to_excel(writer, sheet_name='Combined Results', index=False)

    return metrics_df

# Write results to Excel
metrics_df = write_ragas_results_to_excel(df, results_df, output_file)

print(type(results_df))

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming you have the results from the previous RAGAS evaluation
# If not, you'll need to load or recreate the results

# Metrics to plot
metrics = [
    'context_precision',
    'faithfulness',
    'answer_relevancy',
    'context_recall',
    'answer_correctness',
    'semantic_similarity'
]

# Create a DataFrame to store the metrics
metrics_data = []
for score in results_df.scores:
    metrics_data.append(score)

metrics_df = pd.DataFrame(metrics_data)

# Set up the visualization
plt.figure(figsize=(15, 10))

# 1. Box Plot
plt.subplot(2, 2, 1)
sns.boxplot(data=metrics_df[metrics])
plt.title('Metrics Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 2. Violin Plot
plt.subplot(2, 2, 2)
sns.violinplot(data=metrics_df[metrics])
plt.title('Metrics Density Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 3. Heatmap of Correlations
plt.subplot(2, 2, 3)
sns.heatmap(metrics_df[metrics].corr(), annot=True, cmap='coolwarm', center=0)
plt.title('Metrics Correlation Heatmap')
plt.tight_layout()

# 4. Bar Plot of Mean Metrics
plt.subplot(2, 2, 4)
metrics_means = metrics_df[metrics].mean()
sns.barplot(x=metrics_means.index, y=metrics_means.values)
plt.title('Average Metrics')
plt.xticks(rotation=45)
plt.tight_layout()

# Overall layout adjustments
plt.suptitle('RAG Evaluation Metrics Analysis', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# Save the plot
plt.savefig('rag_metrics_analysis', dpi=300, bbox_inches='tight')

# Print individual metric statistics
print("Metrics Summary:")
for metric in metrics:
    print(f"\n{metric}:")
    print(metrics_df[metric].describe())

"""# non factual"""

metrics_df = write_ragas_results_to_excel(df, results_df, output_file)

# Usage

results_df = evaluate_rag(input_file, output_file)

input_file = 'Non Factual.xlsx'
output_file = f'rag_evaluation_results_ragas'+input_file
# Read input file
df = pd.read_excel(input_file)

# Write results to Excel
metrics_df = write_ragas_results_to_excel(df, results_df, output_file)

print(type(results_df))


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming you have the results from the previous RAGAS evaluation
# If not, you'll need to load or recreate the results

# Metrics to plot
metrics = [
    'context_precision',
    'faithfulness',
    'answer_relevancy',
    'context_recall',
    'answer_correctness',
    'semantic_similarity'
]

# Create a DataFrame to store the metrics
metrics_data = []
for score in results_df.scores:
    metrics_data.append(score)

metrics_df = pd.DataFrame(metrics_data)

# Set up the visualization
plt.figure(figsize=(15, 10))

# 1. Box Plot
plt.subplot(2, 2, 1)
sns.boxplot(data=metrics_df[metrics])
plt.title('Metrics Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 2. Violin Plot
plt.subplot(2, 2, 2)
sns.violinplot(data=metrics_df[metrics])
plt.title('Metrics Density Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 3. Heatmap of Correlations
plt.subplot(2, 2, 3)
sns.heatmap(metrics_df[metrics].corr(), annot=True, cmap='coolwarm', center=0)
plt.title('Metrics Correlation Heatmap')
plt.tight_layout()

# 4. Bar Plot of Mean Metrics
plt.subplot(2, 2, 4)
metrics_means = metrics_df[metrics].mean()
sns.barplot(x=metrics_means.index, y=metrics_means.values)
plt.title('Average Metrics')
plt.xticks(rotation=45)
plt.tight_layout()

# Overall layout adjustments
plt.suptitle('RAG Evaluation Metrics Analysis', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# Save the plot
plt.savefig(f'rag_metrics_analysis_{input_file}.png', dpi=300, bbox_inches='tight')



# Print individual metric statistics
print("Metrics Summary:")
for metric in metrics:
    print(f"\n{metric}:")
    print(metrics_df[metric].describe())

"""# Comparative.xlsx"""

# Usage

results_df = evaluate_rag(input_file, output_file)

input_file = 'Comparative.xlsx'
output_file = f'rag_evaluation_results_ragas'+input_file
# Read input file
df = pd.read_excel(input_file)

# Write results to Excel
metrics_df = write_ragas_results_to_excel(df, results_df, output_file)

print(type(results_df))


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming you have the results from the previous RAGAS evaluation
# If not, you'll need to load or recreate the results

# Metrics to plot
metrics = [
    'context_precision',
    'faithfulness',
    'answer_relevancy',
    'context_recall',
    'answer_correctness',
    'semantic_similarity'
]

# Create a DataFrame to store the metrics
metrics_data = []
for score in results_df.scores:
    metrics_data.append(score)

metrics_df = pd.DataFrame(metrics_data)

# Set up the visualization
plt.figure(figsize=(15, 10))

# 1. Box Plot
plt.subplot(2, 2, 1)
sns.boxplot(data=metrics_df[metrics])
plt.title('Metrics Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 2. Violin Plot
plt.subplot(2, 2, 2)
sns.violinplot(data=metrics_df[metrics])
plt.title('Metrics Density Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 3. Heatmap of Correlations
plt.subplot(2, 2, 3)
sns.heatmap(metrics_df[metrics].corr(), annot=True, cmap='coolwarm', center=0)
plt.title('Metrics Correlation Heatmap')
plt.tight_layout()

# 4. Bar Plot of Mean Metrics
plt.subplot(2, 2, 4)
metrics_means = metrics_df[metrics].mean()
sns.barplot(x=metrics_means.index, y=metrics_means.values)
plt.title('Average Metrics')
plt.xticks(rotation=45)
plt.tight_layout()

# Overall layout adjustments
plt.suptitle('RAG Evaluation Metrics Analysis', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# Save the plot
plt.savefig(f'rag_metrics_analysis_{input_file}.png', dpi=300, bbox_inches='tight')



# Print individual metric statistics
print("Metrics Summary:")
for metric in metrics:
    print(f"\n{metric}:")
    print(metrics_df[metric].describe())

"""# Temporal.xlsx"""

# Usage



input_file = 'Temporal.xlsx'
output_file = f'rag_evaluation_results_ragasyopkk'+input_file

df,results_df = evaluate_rag(input_file, output_file)

# Write results to Excel
metrics_df = write_ragas_results_to_excel(df, results_df, output_file)

print(type(results_df))


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming you have the results from the previous RAGAS evaluation
# If not, you'll need to load or recreate the results

# Metrics to plot
metrics = [
    'context_precision',
    'faithfulness',
    'answer_relevancy',
    'context_recall',
    'answer_correctness',
    'semantic_similarity'
]

# Create a DataFrame to store the metrics
metrics_data = []
for score in results_df.scores:
    metrics_data.append(score)

metrics_df = pd.DataFrame(metrics_data)

# Set up the visualization
plt.figure(figsize=(15, 10))

# 1. Box Plot
plt.subplot(2, 2, 1)
sns.boxplot(data=metrics_df[metrics])
plt.title('Metrics Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 2. Violin Plot
plt.subplot(2, 2, 2)
sns.violinplot(data=metrics_df[metrics])
plt.title('Metrics Density Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 3. Heatmap of Correlations
plt.subplot(2, 2, 3)
sns.heatmap(metrics_df[metrics].corr(), annot=True, cmap='coolwarm', center=0)
plt.title('Metrics Correlation Heatmap')
plt.tight_layout()

# 4. Bar Plot of Mean Metrics
plt.subplot(2, 2, 4)
metrics_means = metrics_df[metrics].mean()
sns.barplot(x=metrics_means.index, y=metrics_means.values)
plt.title('Average Metrics')
plt.xticks(rotation=45)
plt.tight_layout()

# Overall layout adjustments
plt.suptitle(f'RAG Evaluation Metrics Analysis{input_file}', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# Save the plot
plt.savefig(f'rag_metrics_analysis_{input_file}.png', dpi=300, bbox_inches='tight')



# Print individual metric statistics
print("Metrics Summary:")
for metric in metrics:
    print(f"\n{metric}:")
    print(metrics_df[metric].describe())



# Usage



input_file = 'Dialogue.xlsx'
output_file = f'rag_evaluation_results_ragas'+input_file
# Read input file

df,esults_df = evaluate_rag(input_file, output_file)
# Write results to Excel
metrics_df = write_ragas_results_to_excel(df, results_df, output_file)

print(type(results_df))


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming you have the results from the previous RAGAS evaluation
# If not, you'll need to load or recreate the results

# Metrics to plot
metrics = [
    'context_precision',
    'faithfulness',
    'answer_relevancy',
    'context_recall',
    'answer_correctness',
    'semantic_similarity'
]

# Create a DataFrame to store the metrics
metrics_data = []
for score in results_df.scores:
    metrics_data.append(score)

metrics_df = pd.DataFrame(metrics_data)

# Set up the visualization
plt.figure(figsize=(15, 10))

# 1. Box Plot
plt.subplot(2, 2, 1)
sns.boxplot(data=metrics_df[metrics])
plt.title('Metrics Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 2. Violin Plot
plt.subplot(2, 2, 2)
sns.violinplot(data=metrics_df[metrics])
plt.title('Metrics Density Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 3. Heatmap of Correlations
plt.subplot(2, 2, 3)
sns.heatmap(metrics_df[metrics].corr(), annot=True, cmap='coolwarm', center=0)
plt.title('Metrics Correlation Heatmap')
plt.tight_layout()

# 4. Bar Plot of Mean Metrics
plt.subplot(2, 2, 4)
metrics_means = metrics_df[metrics].mean()
sns.barplot(x=metrics_means.index, y=metrics_means.values)
plt.title('Average Metrics')
plt.xticks(rotation=45)
plt.tight_layout()

# Overall layout adjustments
plt.suptitle('RAG Evaluation Metrics Analysis', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# Save the plot
plt.savefig(f'rag_metrics_analysis_{input_file}.png', dpi=300, bbox_inches='tight')



# Print individual metric statistics
print("Metrics Summary:")
for metric in metrics:
    print(f"\n{metric}:")
    print(metrics_df[metric].describe())

# Usage
input_file = 'ALL.xlsx'
output_file = f'rag_evaluation_results_ragas'+input_file
# Read input file

df,esults_df = evaluate_rag(input_file, output_file)
# Write results to Excel
metrics_df = write_ragas_results_to_excel(df, results_df, output_file)

print(type(results_df))


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming you have the results from the previous RAGAS evaluation
# If not, you'll need to load or recreate the results

# Metrics to plot
metrics = [
    'context_precision',
    'faithfulness',
    'answer_relevancy',
    'context_recall',
    'answer_correctness',
    'semantic_similarity'
]

# Create a DataFrame to store the metrics
metrics_data = []
for score in results_df.scores:
    metrics_data.append(score)

metrics_df = pd.DataFrame(metrics_data)

# Set up the visualization
plt.figure(figsize=(15, 10))

# 1. Box Plot
plt.subplot(2, 2, 1)
sns.boxplot(data=metrics_df[metrics])
plt.title('Metrics Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 2. Violin Plot
plt.subplot(2, 2, 2)
sns.violinplot(data=metrics_df[metrics])
plt.title('Metrics Density Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 3. Heatmap of Correlations
plt.subplot(2, 2, 3)
sns.heatmap(metrics_df[metrics].corr(), annot=True, cmap='coolwarm', center=0)
plt.title('Metrics Correlation Heatmap')
plt.tight_layout()

# 4. Bar Plot of Mean Metrics
plt.subplot(2, 2, 4)
metrics_means = metrics_df[metrics].mean()
sns.barplot(x=metrics_means.index, y=metrics_means.values)
plt.title('Average Metrics')
plt.xticks(rotation=45)
plt.tight_layout()

# Overall layout adjustments
plt.suptitle(f'RAG Evaluation Metrics Analysis {input}', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# Save the plot
plt.savefig(f'rag_metrics_analysis_{input_file}.png', dpi=300, bbox_inches='tight')



# Print individual metric statistics
print("Metrics Summary:")
for metric in metrics:
    print(f"\n{metric}:")
    print(metrics_df[metric].describe())

results_df

import pandas as pd
import numpy as np
from ragas import evaluate
from ragas.metrics import (
    context_precision,
    faithfulness,
    answer_relevancy,
    context_recall,
    answer_correctness,
    answer_similarity
)
from datasets import Dataset
import os
import logging
from dotenv import load_dotenv
from langchain_community.vectorstores import Neo4jVector
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_experimental.llms.ollama_functions import OllamaFunctions
from langchain_core.output_parsers import StrOutputParser

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Initialize Local Ollama LLM and Embeddings for both RAG and Evaluation
llm = OllamaFunctions(model="llama3.1", temperature=0.2, format="json")
embeddings = OllamaEmbeddings(model="mxbai-embed-large")
eval_llm = ChatOllama(model="mistral", temperature=0.0, format="json")

# Vector Retriever Setup
vector_index = Neo4jVector.from_existing_graph(
    embeddings,
    search_type="hybrid",
    node_label="Document",
    text_node_properties=["text"],
    embedding_node_property="embedding"
)
vector_retriever = vector_index.as_retriever()

# Retrieval Function (Vector Only)
def vector_only_retriever(question: str, top_k=1):
    """Retrieve top K relevant contexts."""
    vector_data = vector_retriever.invoke(question)[:top_k]  # Get top-k contexts
    return [el.page_content for el in vector_data]  # Return list of top contexts

# Function to break the context into smaller chunks
def chunk_context(context, chunk_size=150):
    """Break the context into chunks of specified size."""
    words = context.split()
    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]
    return chunks

# RAG Chain Setup
template = """Answer the question based only on the following context:
{context}

If the context does not provide enough information, respond with "The context does not contain sufficient information to answer the question."

Use natural language, be concise but detailed where necessary, and do not repeat the question in the answer.

Question: {question}
Answer:
"""
prompt = ChatPromptTemplate.from_template(template)

# Modify chain to handle list context
chain = (
    {
        "context": lambda x: " ".join(vector_only_retriever(x)),  # Retrieve and merge top contexts
        "question": RunnablePassthrough(),
    }
    | prompt
    | llm
    | StrOutputParser()
)

def evaluate_single_ragas(question, ground_truth, model_answer, contexts):
    """Evaluate RAGAS for a single question."""
    try:
        data = {
            'question': [question],
            'ground_truth': [ground_truth],
            'answer': [model_answer],
            'contexts': [contexts]
        }
        dataset = Dataset.from_dict(data)

        result = evaluate(
            dataset,
            metrics=[
                context_precision, faithfulness, answer_relevancy,
                context_recall, answer_correctness, answer_similarity
            ],
            llm=eval_llm,
            embeddings=embeddings,
            show_progress=False,
            batch_size=1
        )

        # ✅ Correctly extract scores from EvaluationResult
        return result.scores  # This is already a dictionary

    except Exception as e:
        logger.error(f"Error during RAGAS evaluation: {str(e)}")
        return None


# Main Evaluation Function
def evaluate_rag(input_file, output_file):
    # Read input Excel file
    df = pd.read_excel(input_file)

    # Generate answers and contexts
    for index, row in df.iterrows():
        question = row['questions']
        ground_truth = row['ground_truths']

        # Get retrieved context (top K relevant) - now a list
        top_contexts = vector_only_retriever(question, top_k=1)

        print(top_contexts)
        print(type(top_contexts))



        # Get model's answer using the final context
        model_answer = chain.invoke(question)

        # Evaluate RAGAS metrics
        metrics = evaluate_single_ragas(question, ground_truth, model_answer, top_contexts)

        #print(metrics)
        #print(type(metrics))

        for k,v in metrics[0].items():
            df.at[index, k] = v

        df.at[index, 'model_answers'] = model_answer
        df.at[index, 'retrieved_contexts'] = str(top_contexts)  # Convert list to string for saving



    df.to_excel(output_file, index=False)

    return df

input_file = 'ALL.xlsx'
output_file = f'bhadve38_rag_evaluation_results_ragasNEWALL560'+input_file
# Read input file
dff=evaluate_rag(input_file,output_file)



ml

def write_ragas_results_to_excel(df, results, output_file):
    # Convert results to a DataFrame


    metrics_df = pd.DataFrame(results)

    # Combine original dataframe with metrics
    combined_df = pd.concat([df, metrics_df], axis=1)

    # Write to Excel
    with pd.ExcelWriter(output_file) as writer:
        combined_df.to_excel(writer, sheet_name='Combined Results', index=False)

    return metrics_df



metrics_df = write_ragas_results_to_excel(df, ml, output_file)

print(type(results_df))


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming you have the results from the previous RAGAS evaluation
# If not, you'll need to load or recreate the results

# Metrics to plot
metrics = [
    'context_precision',
    'faithfulness',
    'answer_relevancy',
    'context_recall',
    'answer_correctness',
    'semantic_similarity'
]

# Create a DataFrame to store the metrics
metrics_data = []
for score in ml.scores:
    metrics_data.append(score)

metrics_df = pd.DataFrame(metrics_data)

# Set up the visualization
plt.figure(figsize=(15, 10))

# 1. Box Plot
plt.subplot(2, 2, 1)
sns.boxplot(data=metrics_df[metrics])
plt.title('Metrics Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 2. Violin Plot
plt.subplot(2, 2, 2)
sns.violinplot(data=metrics_df[metrics])
plt.title('Metrics Density Distribution')
plt.xticks(rotation=45)
plt.tight_layout()

# 3. Heatmap of Correlations
plt.subplot(2, 2, 3)
sns.heatmap(metrics_df[metrics].corr(), annot=True, cmap='coolwarm', center=0)
plt.title('Metrics Correlation Heatmap')
plt.tight_layout()

# 4. Bar Plot of Mean Metrics
plt.subplot(2, 2, 4)
metrics_means = metrics_df[metrics].mean()
sns.barplot(x=metrics_means.index, y=metrics_means.values)
plt.title('Average Metrics')
plt.xticks(rotation=45)
plt.tight_layout()

# Overall layout adjustments
plt.suptitle(f'RAG Evaluation Metrics Analysis {input}', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# Save the plot
plt.savefig(f'rag_metrics_analysis_{input_file}.png', dpi=300, bbox_inches='tight')



# Print individual metric statistics
print("Metrics Summary:")
for metric in metrics:
    print(f"\n{metric}:")
    print(metrics_df[metric].describe())

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_comprehensive_metrics(file_path):
    # Read the Excel file
    df = pd.read_excel(file_path)

    # Select metrics columns
    metrics_columns = [
        'context_precision', 'faithfulness', 'answer_relevancy',
        'context_recall', 'answer_correctness', 'semantic_similarity'
    ]

    # Set up a beautiful color palette
    palette = sns.color_palette("husl", 6)

    # Create a figure with multiple subplots
    plt.figure(figsize=(20, 15))
    plt.suptitle('Comprehensive LLM Performance Metrics Analysis', fontsize=20, fontweight='bold')

    # 1. Violin Plot (Distribution)
    plt.subplot(2, 2, 1)
    df_melted = df[metrics_columns].melt(var_name='Metric', value_name='Score')
    sns.violinplot(x='Metric', y='Score', data=df_melted, palette=palette)
    plt.title('Metric Distributions', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Score', fontsize=12)

    # 2. Box Plot with Individual Points
    plt.subplot(2, 2, 2)
    sns.boxplot(x='Metric', y='Score', data=df_melted, palette=palette)
    sns.stripplot(x='Metric', y='Score', data=df_melted, color='black', size=4, alpha=0.3)
    plt.title('Detailed Metric Breakdown', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Score', fontsize=12)

    # 3. Correlation Heatmap
    plt.subplot(2, 2, 3)
    correlation_matrix = df[metrics_columns].corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                square=True, linewidths=0.5, cbar_kws={"shrink": .8})
    plt.title('Metric Correlations', fontsize=15)

    # 4. Radar Chart
    plt.subplot(2, 2, 4, polar=True)
    mean_metrics = df[metrics_columns].mean()

    # Radar chart setup
    angles = [n / float(len(metrics_columns)) * 2 * np.pi for n in range(len(metrics_columns))]
    angles += angles[:1]

    values = mean_metrics.tolist()
    values += values[:1]

    plt.polar(angles[:-1], values[:-1], 'o-', linewidth=2, label='Mean Metrics')
    plt.fill(angles, values, alpha=0.25)
    plt.xticks(angles[:-1], metrics_columns)
    plt.title('Average Metrics Radar Chart', fontsize=15)

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Detailed Summary Statistics
    print("Comprehensive Metrics Summary:")
    summary = pd.DataFrame({
        'Count': df[metrics_columns].count(),
        'Mean': df[metrics_columns].mean(),
        'Std Dev': df[metrics_columns].std(),
        'Min': df[metrics_columns].min(),
        'Max': df[metrics_columns].max()
    })
    print(summary.round(4))

    # Additional Insights
    print("\nAdditional Insights:")
    for metric in metrics_columns:
        print(f"{metric.replace('_', ' ').title()}:")
        print(f"  Mean: {df[metric].mean():.4f}")
        print(f"  Standard Deviation: {df[metric].std():.4f}")
        print(f"  Coefficient of Variation: {(df[metric].std() / df[metric].mean() * 100):.2f}%")

    plt.show()

# Usage
# plot_comprehensive_metrics('your_excel_file.xlsx')
file_path = 'bhadve38_rag_evaluation_results_ragasNEWALL560ALL.xlsx'
plot_comprehensive_metrics(file_path)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_comprehensive_metrics(file_path):
    # Read the Excel file
    df = pd.read_excel(file_path)

    # Select metrics columns
    metrics_columns = [
        'context_precision', 'faithfulness', 'answer_relevancy',
        'context_recall', 'answer_correctness', 'semantic_similarity'
    ]

    # Set up a beautiful color palette
    palette = sns.color_palette("husl", 6)

    # Create a figure with multiple subplots
    plt.figure(figsize=(20, 20))
    plt.suptitle('Comprehensive LLM Performance Metrics Analysis', fontsize=20, fontweight='bold')

    # Adjust subplot layout to make room for the new mean bar plot
    plt.subplots_adjust(hspace=0.3, wspace=0.3)

    # 1. Violin Plot (Distribution)
    plt.subplot(2, 2, 1)
    df_melted = df[metrics_columns].melt(var_name='Metric', value_name='Score')
    sns.violinplot(x='Metric', y='Score', data=df_melted, palette=palette)
    plt.title('Metric Distributions', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Score', fontsize=12)

    # 2. Box Plot with Individual Points
    plt.subplot(2, 2, 2)
    sns.boxplot(x='Metric', y='Score', data=df_melted, palette=palette)
    sns.stripplot(x='Metric', y='Score', data=df_melted, color='black', size=4, alpha=0.3)
    plt.title('Detailed Metric Breakdown', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Score', fontsize=12)

    # 3. Correlation Heatmap
    plt.subplot(2, 2, 3)
    correlation_matrix = df[metrics_columns].corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                square=True, linewidths=0.5, cbar_kws={"shrink": .8})
    plt.title('Metric Correlations', fontsize=15)

    # 4. Radar Chart
    plt.subplot(2, 2, 4, polar=True)
    mean_metrics = df[metrics_columns].mean()

    # Radar chart setup
    angles = [n / float(len(metrics_columns)) * 2 * np.pi for n in range(len(metrics_columns))]
    angles += angles[:1]

    values = mean_metrics.tolist()
    values += values[:1]

    plt.polar(angles[:-1], values[:-1], 'o-', linewidth=2, label='Mean Metrics')
    plt.fill(angles, values, alpha=0.25)
    plt.xticks(angles[:-1], metrics_columns)
    plt.title('Average Metrics Radar Chart', fontsize=15)

    # 5. Mean Values Bar Plot (New subplot)
    plt.subplot(2, 2, 5)
    mean_values = df[metrics_columns].mean()
    plt.bar(metrics_columns, mean_values, color=palette)
    plt.title('Mean Values of Metrics', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Average Score', fontsize=12)

    # Add value labels on top of each bar
    for i, v in enumerate(mean_values):
        plt.text(i, v, f'{v:.3f}', ha='center', va='bottom')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Detailed Summary Statistics
    print("Comprehensive Metrics Summary:")
    summary = pd.DataFrame({
        'Count': df[metrics_columns].count(),
        'Mean': df[metrics_columns].mean(),
        'Std Dev': df[metrics_columns].std(),
        'Min': df[metrics_columns].min(),
        'Max': df[metrics_columns].max()
    })
    print(summary.round(4))

    # Additional Insights
    print("\nAdditional Insights:")
    for metric in metrics_columns:
        print(f"{metric.replace('_', ' ').title()}:")
        print(f"  Mean: {df[metric].mean():.4f}")
        print(f"  Standard Deviation: {df[metric].std():.4f}")
        print(f"  Coefficient of Variation: {(df[metric].std() / df[metric].mean() * 100):.2f}%")

    plt.show()

# Usage
plot_comprehensive_metrics('bhadve38_rag_evaluation_results_ragasNEWALL560ALL.xlsx')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_comprehensive_metrics(file_path):
    # Read the Excel file
    df = pd.read_excel(file_path)

    # Select metrics columns
    metrics_columns = [
        'context_precision', 'faithfulness', 'answer_relevancy',
        'context_recall', 'answer_correctness', 'semantic_similarity'
    ]

    # Set up a beautiful color palette
    palette = sns.color_palette("husl", 6)

    # Create a figure with multiple subplots
    plt.figure(figsize=(20, 25))
    plt.suptitle('Comprehensive LLM Performance Metrics Analysis', fontsize=20, fontweight='bold')

    # Adjust subplot layout
    plt.subplots_adjust(hspace=0.4, wspace=0.3)

    # 1. Violin Plot (Distribution)
    plt.subplot(3, 2, 1)
    df_melted = df[metrics_columns].melt(var_name='Metric', value_name='Score')
    sns.violinplot(x='Metric', y='Score', data=df_melted, palette=palette)
    plt.title('Metric Distributions', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Score', fontsize=12)

    # 2. Box Plot with Individual Points
    plt.subplot(3, 2, 2)
    sns.boxplot(x='Metric', y='Score', data=df_melted, palette=palette)
    sns.stripplot(x='Metric', y='Score', data=df_melted, color='black', size=4, alpha=0.3)
    plt.title('Detailed Metric Breakdown', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Score', fontsize=12)

    # 3. Correlation Heatmap
    plt.subplot(3, 2, 3)
    correlation_matrix = df[metrics_columns].corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                square=True, linewidths=0.5, cbar_kws={"shrink": .8})
    plt.title('Metric Correlations', fontsize=15)

    # 4. Radar Chart
    plt.subplot(3, 2, 4, polar=True)
    mean_metrics = df[metrics_columns].mean()

    # Radar chart setup
    angles = [n / float(len(metrics_columns)) * 2 * np.pi for n in range(len(metrics_columns))]
    angles += angles[:1]

    values = mean_metrics.tolist()
    values += values[:1]

    plt.polar(angles[:-1], values[:-1], 'o-', linewidth=2, label='Mean Metrics')
    plt.fill(angles, values, alpha=0.25)
    plt.xticks(angles[:-1], metrics_columns)
    plt.title('Average Metrics Radar Chart', fontsize=15)

    # 5. Mean Values Bar Plot
    plt.subplot(3, 2, 5)
    mean_values = df[metrics_columns].mean()
    plt.bar(metrics_columns, mean_values, color=palette)
    plt.title('Mean Values of Metrics', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Average Score', fontsize=12)

    # Add value labels on top of each bar
    for i, v in enumerate(mean_values):
        plt.text(i, v, f'{v:.3f}', ha='center', va='bottom')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Detailed Summary Statistics
    print("Comprehensive Metrics Summary:")
    summary = pd.DataFrame({
        'Count': df[metrics_columns].count(),
        'Mean': df[metrics_columns].mean(),
        'Std Dev': df[metrics_columns].std(),
        'Min': df[metrics_columns].min(),
        'Max': df[metrics_columns].max()
    })
    print(summary.round(4))

    # Additional Insights
    print("\nAdditional Insights:")
    for metric in metrics_columns:
        print(f"{metric.replace('_', ' ').title()}:")
        print(f"  Mean: {df[metric].mean():.4f}")
        print(f"  Standard Deviation: {df[metric].std():.4f}")
        print(f"  Coefficient of Variation: {(df[metric].std() / df[metric].mean() * 100):.2f}%")

    plt.show()

# Usage
df = pd.read_excel(file_path)
plot_comprehensive_metrics('bhadve38_rag_evaluation_results_ragasNEWALL560ALL.xlsx')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_comprehensive_metrics(file_path):
    # Read the Excel file
    df = pd.read_excel(file_path)

    # Select metrics columns
    metrics_columns = [
        'context_precision', 'faithfulness', 'answer_relevancy',
        'context_recall', 'answer_correctness', 'semantic_similarity'
    ]

    # Set up a beautiful color palette
    palette = sns.color_palette("husl", 6)

    # Create a figure with multiple subplots
    plt.figure(figsize=(20, 25))
    plt.suptitle('Comprehensive LLM Performance Metrics Analysis', fontsize=20, fontweight='bold')

    # Adjust subplot layout
    plt.subplots_adjust(hspace=0.4, wspace=0.3)

    # 1. Violin Plot (Distribution)
    plt.subplot(3, 2, 1)
    df_melted = df[metrics_columns].melt(var_name='Metric', value_name='Score')
    sns.violinplot(x='Metric', y='Score', data=df_melted, palette=palette)
    plt.title('Metric Distributions', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Score', fontsize=12)

    # 2. Box Plot with Individual Points
    plt.subplot(3, 2, 2)
    sns.boxplot(x='Metric', y='Score', data=df_melted, palette=palette)
    sns.stripplot(x='Metric', y='Score', data=df_melted, color='black', size=4, alpha=0.3)
    plt.title('Detailed Metric Breakdown', fontsize=15)
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Score', fontsize=12)

    # 3. Correlation Heatmap
    plt.subplot(3, 2, 3)
    correlation_matrix = df[metrics_columns].corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                square=True, linewidths=0.5, cbar_kws={"shrink": .8})
    plt.title('Metric Correlations', fontsize=15)

    # 4. Radar Chart
    plt.subplot(3, 2, 4, polar=True)
    mean_metrics = df[metrics_columns].mean()
    median_metrics = df[metrics_columns].median()

    # Radar chart setup
    angles = [n / float(len(metrics_columns)) * 2 * np.pi for n in range(len(metrics_columns))]
    angles += angles[:1]

    mean_values = mean_metrics.tolist() + mean_metrics.tolist()[:1]
    median_values = median_metrics.tolist() + median_metrics.tolist()[:1]

    plt.polar(angles[:-1], mean_values[:-1], 'o-', linewidth=2, label='Mean Metrics', color='blue')
    plt.polar(angles[:-1], median_values[:-1], 'o-', linewidth=2, linestyle='dashed', label='Median Metrics', color='red')
    plt.fill(angles, mean_values, alpha=0.25, color='blue')
    plt.fill(angles, median_values, alpha=0.15, color='red')
    plt.xticks(angles[:-1], metrics_columns)
    plt.title('Mean vs. Median Metrics Radar Chart', fontsize=15)
    plt.legend()

    # 5. Mean & Median Bar Plot
    plt.subplot(3, 2, 5)
    mean_values = df[metrics_columns].mean()
    median_values = df[metrics_columns].median()

    x = np.arange(len(metrics_columns))
    width = 0.35  # Bar width

    plt.bar(x - width/2, mean_values, width, label='Mean', color='blue')
    plt.bar(x + width/2, median_values, width, label='Median', color='red')

    plt.xticks(x, metrics_columns, rotation=45, ha='right')
    plt.title('Mean vs. Median of Metrics', fontsize=15)
    plt.ylabel('Score', fontsize=12)
    plt.legend()

    # Add value labels
    for i, v in enumerate(mean_values):
        plt.text(i - width/2, v, f'{v:.3f}', ha='center', va='bottom', fontsize=10, color='blue')
    for i, v in enumerate(median_values):
        plt.text(i + width/2, v, f'{v:.3f}', ha='center', va='bottom', fontsize=10, color='red')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Detailed Summary Statistics
    print("Comprehensive Metrics Summary:")
    summary = pd.DataFrame({
        'Count': df[metrics_columns].count(),
        'Mean': df[metrics_columns].mean(),
        'Median': df[metrics_columns].median(),
        'Std Dev': df[metrics_columns].std(),
        'Min': df[metrics_columns].min(),
        'Max': df[metrics_columns].max()
    })
    print(summary.round(4))

    # Additional Insights
    print("\nAdditional Insights:")
    for metric in metrics_columns:
        mean_val = df[metric].mean()
        median_val = df[metric].median()
        std_dev = df[metric].std()
        coeff_var = (std_dev / mean_val * 100) if mean_val != 0 else 0
        print(f"{metric.replace('_', ' ').title()}:")
        print(f"  Mean: {mean_val:.4f}")
        print(f"  Median: {median_val:.4f}")
        print(f"  Standard Deviation: {std_dev:.4f}")
        print(f"  Coefficient of Variation: {coeff_var:.2f}%")

    plt.show()

# Usage
plot_comprehensive_metrics('bhadve38_rag_evaluation_results_ragasNEWALL560ALL.xlsx')

plt.figure(figsize=(10, 6))
sns.violinplot(data=df[['context_precision', 'faithfulness', 'answer_relevancy',
                        'context_recall', 'answer_correctness', 'semantic_similarity']])
plt.xticks(rotation=45)
plt.title('Violin Plot of Metrics')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_category_wise_metrics(file_path):
    # Read the Excel file
    df = pd.read_excel(file_path)

    # Select metric columns
    metrics_columns = [
        'context_precision', 'faithfulness', 'answer_relevancy',
        'context_recall', 'answer_correctness', 'semantic_similarity'
    ]

    # Identify unique categories in the first column
    df['Category'] = df.iloc[:, 0].where(df.iloc[:, 0].str.startswith('###')).ffill()
    categories = df['Category'].unique()

    # Prepare to store summary metrics
    summary_data = []

    # Create a figure for plots
    plt.figure(figsize=(20, len(categories) * 5))
    plt.suptitle('Category-wise LLM Performance Metrics Analysis', fontsize=20, fontweight='bold')

    # Iterate through categories
    for i, category in enumerate(categories, 1):
        category_df = df[df['Category'] == category]

        # Compute Mean & Median for category
        mean_values = category_df[metrics_columns].mean()
        median_values = category_df[metrics_columns].median()
        summary_data.append([category] + mean_values.tolist() + median_values.tolist())

        # Subplot for each category
        plt.subplot(len(categories), 2, i)
        x = np.arange(len(metrics_columns))
        width = 0.3

        plt.bar(x - width/2, mean_values, width, label='Mean', color='blue', alpha=0.7)
        plt.bar(x + width/2, median_values, width, label='Median', color='red', alpha=0.7)
        plt.xticks(x, metrics_columns, rotation=45, ha='right')
        plt.ylabel('Score')
        plt.title(f'Metrics for {category}')
        plt.legend()

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Create a summary DataFrame
    summary_df = pd.DataFrame(summary_data, columns=['Category'] +
                              [f'Mean_{m}' for m in metrics_columns] +
                              [f'Median_{m}' for m in metrics_columns])

    print("\nCategory-wise Metrics Summary:")
    print(summary_df.round(4))

    plt.show()

# Usage
plot_category_wise_metrics('seperated_bhadve.xlsx')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_metrics_by_question_type(file_path):
    # Read the Excel file
    df = pd.read_excel(file_path)

    # Identify unique question types (rows where the first column starts with ###)
    df['Question_Type'] = df.iloc[:, 0].where(df.iloc[:, 0].astype(str).str.startswith('###')).ffill()

    # Select metrics columns
    metrics_columns = [
        'context_precision', 'faithfulness', 'answer_relevancy',
        'context_recall', 'answer_correctness', 'semantic_similarity'
    ]

    # Set up color palette
    palette = sns.color_palette("husl", 6)

    # Process each question type separately
    for question_type in df['Question_Type'].unique():
        subset_df = df[df['Question_Type'] == question_type]

        if subset_df.empty:
            continue

        print(f"\n=== Processing Metrics for: {question_type} ===\n")

        # Melt data for plots
        df_melted = subset_df[metrics_columns].melt(var_name='Metric', value_name='Score')

        # Create a figure
        plt.figure(figsize=(20, 25))
        plt.suptitle(f'Metrics Analysis for {question_type}', fontsize=20, fontweight='bold')

        # 1. Violin Plot (Distribution)
        plt.subplot(3, 2, 1)
        sns.violinplot(x='Metric', y='Score', data=df_melted, palette=palette)
        plt.title('Metric Distributions', fontsize=15)
        plt.xticks(rotation=45, ha='right')
        plt.ylabel('Score', fontsize=12)

        # 2. Box Plot with Individual Points
        plt.subplot(3, 2, 2)
        sns.boxplot(x='Metric', y='Score', data=df_melted, palette=palette)
        sns.stripplot(x='Metric', y='Score', data=df_melted, color='black', size=4, alpha=0.3)
        plt.title('Detailed Metric Breakdown', fontsize=15)
        plt.xticks(rotation=45, ha='right')
        plt.ylabel('Score', fontsize=12)

        # 3. Correlation Heatmap
        plt.subplot(3, 2, 3)
        correlation_matrix = subset_df[metrics_columns].corr()
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                    square=True, linewidths=0.5, cbar_kws={"shrink": .8})
        plt.title('Metric Correlations', fontsize=15)

        # 4. Radar Chart
        plt.subplot(3, 2, 4, polar=True)
        mean_metrics = subset_df[metrics_columns].mean()
        median_metrics = subset_df[metrics_columns].median()

        # Radar chart setup
        angles = [n / float(len(metrics_columns)) * 2 * np.pi for n in range(len(metrics_columns))]
        angles += angles[:1]

        mean_values = mean_metrics.tolist() + mean_metrics.tolist()[:1]
        median_values = median_metrics.tolist() + median_metrics.tolist()[:1]

        plt.polar(angles[:-1], mean_values[:-1], 'o-', linewidth=2, label='Mean Metrics', color='blue')
        plt.polar(angles[:-1], median_values[:-1], 'o-', linewidth=2, linestyle='dashed', label='Median Metrics', color='red')
        plt.fill(angles, mean_values, alpha=0.25, color='blue')
        plt.fill(angles, median_values, alpha=0.15, color='red')
        plt.xticks(angles[:-1], metrics_columns)
        plt.title('Mean vs. Median Metrics Radar Chart', fontsize=15)
        plt.legend()

        # 5. Mean & Median Bar Plot
        plt.subplot(3, 2, 5)
        mean_values = subset_df[metrics_columns].mean()
        median_values = subset_df[metrics_columns].median()

        x = np.arange(len(metrics_columns))
        width = 0.35  # Bar width

        plt.bar(x - width/2, mean_values, width, label='Mean', color='blue')
        plt.bar(x + width/2, median_values, width, label='Median', color='red')

        plt.xticks(x, metrics_columns, rotation=45, ha='right')
        plt.title('Mean vs. Median of Metrics', fontsize=15)
        plt.ylabel('Score', fontsize=12)
        plt.legend()

        # Add value labels
        for i, v in enumerate(mean_values):
            plt.text(i - width/2, v, f'{v:.3f}', ha='center', va='bottom', fontsize=10, color='blue')
        for i, v in enumerate(median_values):
            plt.text(i + width/2, v, f'{v:.3f}', ha='center', va='bottom', fontsize=10, color='red')

        plt.tight_layout(rect=[0, 0.03, 1, 0.95])

        # Detailed Summary Statistics
        print("Metrics Summary for:", question_type)
        summary = pd.DataFrame({
            'Count': subset_df[metrics_columns].count(),
            'Mean': subset_df[metrics_columns].mean(),
            'Median': subset_df[metrics_columns].median(),
            'Std Dev': subset_df[metrics_columns].std(),
            'Min': subset_df[metrics_columns].min(),
            'Max': subset_df[metrics_columns].max()
        })
        print(summary.round(4))

        # Additional Insights
        print("\nAdditional Insights:")
        for metric in metrics_columns:
            mean_val = subset_df[metric].mean()
            median_val = subset_df[metric].median()
            std_dev = subset_df[metric].std()
            coeff_var = (std_dev / mean_val * 100) if mean_val != 0 else 0
            print(f"{metric.replace('_', ' ').title()}:")
            print(f"  Mean: {mean_val:.4f}")
            print(f"  Median: {median_val:.4f}")
            print(f"  Standard Deviation: {std_dev:.4f}")
            print(f"  Coefficient of Variation: {coeff_var:.2f}%")

        plt.show()

# Usage
plot_metrics_by_question_type('seperated_bhadve.xlsx')
#plot_metrics_by_question_type('bhadve38_rag_evaluation_results_ragasNEWALL560ALL.xlsx')